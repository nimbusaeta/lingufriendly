{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 10: Procesamiento del Lenguaje Natural (IV) - WordNet\n",
    "En este cuaderno vamos a aprender qué es WordNet y algunas de las cosas más útiles que se pueden hacer con esta librería, como explorar sinónimos, obtener traducciones contextuales, explorar relaciones de hiperonimia y holonimia, y abordar algunas de las cuestiones más ambiciosas del PLN: la expansión de búsquedas, el cálculo de la distancia semántica o la desambiguación.\n",
    "\n",
    "En este cuaderno no hay ejercicios al final, pero hay mucho espacio a la experimentación con otras palabras, otros synsets, otros idiomas... a lo largo de toda la lección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet # Importamos WordNet\n",
    "from IPython.display import HTML, display, Image # Importamos una serie de clases y funciones útiles\n",
    "\n",
    "def display_table(data, headers=None, caption=None):\n",
    "    ''' Una función para imprimir tablas en formato HTML, solo por estética\n",
    "    '''\n",
    "    html = [\"<table align=\\\"left\\\">\"]\n",
    "    \n",
    "    if caption:\n",
    "        html += [\"<caption>{}</caption>\".format(caption)]\n",
    "        \n",
    "    if headers:\n",
    "        html += [\"<tr>\"] + [\"<th>{}</th>\".format(h) for h in headers] + [\"</tr>\"]\n",
    "    \n",
    "    for row in data:\n",
    "        html += [\"<tr>\"]\n",
    "        html += [\"<td>{}</td>\".format(it) for it in row]\n",
    "        html += [\"</tr>\"]\n",
    "\n",
    "    html.append(\"</table>\")\n",
    "    display(HTML(''.join(html)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) es una red de conceptos que contiene información codificada manualmente sobre sustantivos, verbos, adjetivos y adverbios en inglés; los términos que representan un mismo concepto están agrupados en _synsets_ y son estos elementos los que constituyen los nodos de la red.\n",
    "\n",
    "WordNet se creó en el Laboratorio de Ciencia Cognitiva de la Universidad de Princeton en 1985 bajo la dirección del profesor de psicología George Armitage Miller (1920-2012).\n",
    "\n",
    "Para que nos hagamos una idea de la cantidad de información que contiene ([más números](http://wordnet.princeton.edu/wordnet/man/wnstats.7WN.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Qué hay dentro de WordNet?\n",
      "Hay 82115 nombres.\n",
      "Hay 13767 verbos.\n",
      "Hay 18156 adjetivos.\n",
      "Hay 3621 adverbios.\n"
     ]
    }
   ],
   "source": [
    "n_nouns = len(list(wordnet.all_synsets(pos=wordnet.NOUN)))\n",
    "n_verbs = len(list(wordnet.all_synsets(pos=wordnet.VERB)))\n",
    "n_adj = len(list(wordnet.all_synsets(pos=wordnet.ADJ)))\n",
    "n_adv = len(list(wordnet.all_synsets(pos=wordnet.ADV)))\n",
    "\n",
    "print(\"¿Qué hay dentro de WordNet?\")\n",
    "print(\"Hay {} nombres.\".format(n_nouns))\n",
    "print(\"Hay {} verbos.\".format(n_verbs))\n",
    "print(\"Hay {} adjetivos.\".format(n_adj))\n",
    "print(\"Hay {} adverbios.\".format(n_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Observa lo que hace el método `format()`: recibe como parámetro una variable, y se aplica a una string que debe contener `{}`. En vez de estos corchetes, imprime la variable, y como ves no hace falta convertirla a string previamente.)\n",
    "## Synsets\n",
    "Un _synset_ (_syonyms set_) es un conjunto de sinónimos, palabras de la misma categoría gramatical que hacen referencia a la misma realidad extralingüística y por lo tanto pueden ser intercambiadas en un texto sin afectar al significado. Son elementos semánticamente equivalentes. Así, ocurrirá que las palabras polisémicas aparecerán en muchos synsets diferentes.\n",
    "\n",
    "Podemos hacer una búsqueda de uno de estos synsets pasándole el término de búsqueda que elijamos a la función `synsets()` como string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta palabra pertenece a 13 synsets distintos:\n",
      "[Synset('bed.n.01'), Synset('bed.n.02'), Synset('bed.n.03'), Synset('bed.n.04'), Synset('seam.n.03'), Synset('layer.n.01'), Synset('bed.n.07'), Synset('bed.n.08'), Synset('bed.v.01'), Synset('bed.v.02'), Synset('bed.v.03'), Synset('sleep_together.v.01'), Synset('go_to_bed.v.01')]\n",
      "<class 'nltk.corpus.reader.wordnet.Synset'>\n"
     ]
    }
   ],
   "source": [
    "my_synsets = wordnet.synsets('bed')\n",
    "print(\"Esta palabra pertenece a\", len(my_synsets), \"synsets distintos:\")\n",
    "\n",
    "print(my_synsets)\n",
    "print(type(my_synsets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos devuelve una lista de objetos de tipo Synset, como podemos ver. Estos objetos tienen varios atributos interesantes para explorar, como `name` o `definition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>Synset</th><th>Definición</th></tr><tr><td>bed.n.01</td><td>a piece of furniture that provides a place to sleep</td></tr><tr><td>bed.n.02</td><td>a plot of ground in which plants are growing</td></tr><tr><td>bed.n.03</td><td>a depression forming the ground under a body of water</td></tr><tr><td>bed.n.04</td><td>(geology) a stratum of rock (especially sedimentary rock)</td></tr><tr><td>seam.n.03</td><td>a stratum of ore or coal thick enough to be mined with profit</td></tr><tr><td>layer.n.01</td><td>single thickness of usually some homogeneous substance</td></tr><tr><td>bed.n.07</td><td>the flat surface of a printing press on which the type form is laid in the last stage of producing a newspaper or magazine or book etc.</td></tr><tr><td>bed.n.08</td><td>a foundation of earth or rock supporting a road or railroad track</td></tr><tr><td>bed.v.01</td><td>furnish with a bed</td></tr><tr><td>bed.v.02</td><td>place (plants) in a prepared bed of soil</td></tr><tr><td>bed.v.03</td><td>put to bed</td></tr><tr><td>sleep_together.v.01</td><td>have sexual intercourse with</td></tr><tr><td>go_to_bed.v.01</td><td>prepare for sleep</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for synset in my_synsets:\n",
    "    data.append([synset.name(), synset.definition()])\n",
    "\n",
    "display_table(data, [\"Synset\", \"Definición\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos quedarnos con uno de ellos y explorar la cantidad de información que ofrece WordNet una vez que hemos encontrado el synset que nos interesa (pero puedes probar con otros: `my_synsets[0]`, `my_synsets[1]`...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synset.name: sleep_together.v.01\n",
      "synset.definition: have sexual intercourse with\n",
      "synset.examples:\n",
      "\t + This student sleeps with everyone in her dorm\n",
      "\t + Adam knew Eve\n",
      "\t + Were you ever intimate with this man?\n",
      "synset.lemmas:\n",
      "\t + sleep_together\n",
      "\t + roll_in_the_hay\n",
      "\t + love\n",
      "\t + make_out\n",
      "\t + make_love\n",
      "\t + sleep_with\n",
      "\t + get_laid\n",
      "\t + have_sex\n",
      "\t + know\n",
      "\t + do_it\n",
      "\t + be_intimate\n",
      "\t + have_intercourse\n",
      "\t + have_it_away\n",
      "\t + have_it_off\n",
      "\t + screw\n",
      "\t + fuck\n",
      "\t + jazz\n",
      "\t + eff\n",
      "\t + hump\n",
      "\t + lie_with\n",
      "\t + bed\n",
      "\t + have_a_go_at_it\n",
      "\t + bang\n",
      "\t + get_it_on\n",
      "\t + bonk\n"
     ]
    }
   ],
   "source": [
    "my_synset = my_synsets[11]\n",
    "print(\"synset.name: {}\".format(my_synset.name()))\n",
    "print(\"synset.definition: {}\".format(my_synset.definition()))\n",
    "\n",
    "print(\"synset.examples:\")\n",
    "for example in my_synset.examples():\n",
    "    print(\"\\t + {}\".format(example))\n",
    "\n",
    "print(\"synset.lemmas:\")\n",
    "for lemma in my_synset.lemmas():\n",
    "    print(\"\\t + {}\".format(lemma.name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos buscar los lemmas correspondientes a un synset en otros idiomas. Vamos a mostrar aquí solo un ejemplo porque trataremos este tema más adelante. Véamos cuáles son los relacionados con el synset que hemos guardado en la variable `my_synset` de la celda anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idiomas disponibles: als, arb, bul, cat, cmn, dan, ell, eng, eus, fas, fin, fra, glg, heb, hrv, ind, ita, jpn, nld, nno, nob, pol, por, qcn, slv, spa, swe, tha, zsm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>lang</th><th>lemmas</th></tr><tr><td>eng</td><td>sleep_together</br>roll_in_the_hay</br>love</br>make_out</br>make_love</br>sleep_with</br>get_laid</br>have_sex</br>know</br>do_it</br>be_intimate</br>have_intercourse</br>have_it_away</br>have_it_off</br>screw</br>fuck</br>jazz</br>eff</br>hump</br>lie_with</br>bed</br>have_a_go_at_it</br>bang</br>get_it_on</br>bonk</td></tr><tr><td>spa</td><td>joder</td></tr><tr><td>fra</td><td>aimer</br>avoir</br>avoir_des_relations_sexuelles</br>baiser</br>bien</br>connaître</br>enconner</br>enculer</br>faire_l'amour</br>fourrer</br>foutre</br>niquer</br>savoir</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = sorted(wordnet.langs())\n",
    "print(\"Idiomas disponibles: {}\".format(', '.join(languages)))\n",
    "\n",
    "selected_languages = ['eng', 'spa', 'fra'] # Puedes probar con otros idiomas de la lista\n",
    "\n",
    "data = []\n",
    "for lang in selected_languages:\n",
    "    data.append([lang, '</br>'.join(my_synset.lemma_names(lang))])\n",
    "\n",
    "display_table(data, headers=[\"lang\", \"lemmas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, hay que ampliar el vocabulario que contiene en español...\n",
    "### Categoría gramatical de un synset\n",
    "En el apartado anterior hemos recuperado todos los synsets a partir de una palabra y nos han aparecido significados correspondientes a sustantivos, verbos, adjetivos... pero se puede afinar un poco más la búsqueda utilizando la PoS:\n",
    "\n",
    " - `wordnet.VERB`\n",
    " - `wordnet.NOUN`\n",
    " - `wordnet.ADJ`\n",
    " - `wordnet.ADV`\n",
    " \n",
    "¡Vamos a verlo en acción!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets_as_noun: [Synset('commodity.n.01'), Synset('good.n.03'), Synset('sake.n.01'), Synset('good.n.01'), Synset('personal_property.n.01')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Resultados con: wordnet.NOUN</caption><tr><th>Synset</th><th>Lemmas</th><th>Definición</th></tr><tr><td>commodity.n.01</td><td>['commodity', 'trade_good', 'good']</td><td>articles of commerce</td></tr><tr><td>good.n.03</td><td>['good', 'goodness']</td><td>that which is pleasing or valuable or useful</td></tr><tr><td>sake.n.01</td><td>['sake', 'interest']</td><td>a reason for wanting something done</td></tr><tr><td>good.n.01</td><td>['good']</td><td>benefit</td></tr><tr><td>personal_property.n.01</td><td>['personal_property', 'personal_estate', 'personalty', 'private_property']</td><td>movable property (as distinguished from real estate)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Resultados con: wordnet.VERB</caption><tr><th>Synset</th><th>Lemmas</th><th>Definición</th></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Resultados con: wordnet.ADJ</caption><tr><th>Synset</th><th>Lemmas</th><th>Definición</th></tr><tr><td>good.s.17</td><td>['good', 'sound']</td><td>in excellent physical condition</td></tr><tr><td>all_right.s.01</td><td>['all_right', 'fine', 'o.k.', 'ok', 'okay', 'hunky-dory']</td><td>being satisfactory or in satisfactory condition</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Resultados con: wordnet.ADV</caption><tr><th>Synset</th><th>Lemmas</th><th>Definición</th></tr><tr><td>well.r.13</td><td>['well']</td><td>without unusual distress or resentment; with good humor</td></tr><tr><td>well.r.06</td><td>['well']</td><td>favorably; with approval</td></tr><tr><td>well.r.12</td><td>['well', 'comfortably']</td><td>in financial comfort</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"bien\" # Puedes probar con otras palabras que correspondan a varias categorías gramaticales\n",
    "lang = \"spa\"\n",
    "\n",
    "synsets_as_noun = wordnet.synsets(word, lang=lang, pos=wordnet.NOUN)\n",
    "synsets_as_verb = wordnet.synsets(word, lang=lang, pos=wordnet.VERB)\n",
    "synsets_as_adj = wordnet.synsets(word, lang=lang, pos=wordnet.ADJ)\n",
    "synsets_as_adv = wordnet.synsets(word, lang=lang, pos=wordnet.ADV)\n",
    "\n",
    "# Vamos a imprimir los resultados\n",
    "print(\"synsets_as_noun: {}\".format(synsets_as_noun))\n",
    "\n",
    "def synset_table(synsets, title):\n",
    "    data = []\n",
    "    for synset in synsets:\n",
    "        data.append([synset.name(), synset.lemma_names(), synset.definition()])\n",
    "        \n",
    "    display_table(data, [\"Synset\", \"Lemmas\", \"Definición\"], caption=title)\n",
    "\n",
    "synset_table(synsets_as_noun, title=\"Resultados con: wordnet.NOUN\")\n",
    "synset_table(synsets_as_verb, title=\"Resultados con: wordnet.VERB\")\n",
    "synset_table(synsets_as_adj,  title=\"Resultados con: wordnet.ADJ\")\n",
    "synset_table(synsets_as_adv, title=\"Resultados con: wordnet.ADV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperar, la tabla de verbos ha salido vacía porque en ningún caso \"bien\" actúa como verbo.\n",
    "### Lo interesante de los synsets\n",
    "Lo interesante de los synsets es que permiten referirse a un significado sin ambigüedades. A los ordenadores se les da muy mal resolver ambigüedades, generalmente se les da muy mal todo lo que humanos hacemos con relativa facilidad (entender un mensaje, reconocer imágenes...), pero realizan muy eficazmente tareas que a nosotros nos cuestan mucho tiempo (búsquedas, ordenación...).\n",
    "\n",
    "Los ordenadores querrían ver los textos de esta forma, **sin ambigüedades**:\n",
    "\n",
    "```\n",
    "El perro ladra ---> El dog.n.01 bark.v.04\n",
    "```\n",
    "así podrían entenderlo y podríamos hacer inferencias sin equivocarnos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas\n",
    "\n",
    "No debe confundirse un **synset** con un **lemma**, tal y como los identifica WordNet. Recordemos que:\n",
    " \n",
    " * un **synset** está asociado a un significado, que puede representarse en lenguaje natural mediante palabras (lemmas) muy diferentes: \"perro\", \"dog\", \"can\"...\n",
    " * un **lemma** es una palabra de lenguaje natural y, por lo tanto, puede tener varios significados (synsets).\n",
    " \n",
    "Esta diferencia es importantísima tenerla presente.\n",
    "\n",
    "Como vemos, a través de un synset llegamos a lemmas diferentes, pero todos ellos con el mismo significado. De hecho, el identificador del sysnset `dog.n.01` se mantiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01') -> Lemma('dog.n.01.dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.domestic_dog')\n",
      "Synset('dog.n.01') -> Lemma('dog.n.01.Canis_familiaris')\n"
     ]
    }
   ],
   "source": [
    "ex_synset = wordnet.synset('dog.n.01')\n",
    "for lemma in ex_synset.lemmas():\n",
    "    print(\"{} -> {}\".format(ex_synset, lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, cuando buscamos una palabra obtenemos varios lemmas, cada uno de ellos asociado a un synset diferente. Se puede observar cómo los identificadores de los synsets son diferentes: `dog.n.01`, `frump.n.01`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog -> Lemma('dog.n.01.dog') -> Synset('dog.n.01')\n",
      "dog -> Lemma('frump.n.01.dog') -> Synset('frump.n.01')\n",
      "dog -> Lemma('dog.n.03.dog') -> Synset('dog.n.03')\n",
      "dog -> Lemma('cad.n.01.dog') -> Synset('cad.n.01')\n",
      "dog -> Lemma('frank.n.02.dog') -> Synset('frank.n.02')\n",
      "dog -> Lemma('pawl.n.01.dog') -> Synset('pawl.n.01')\n",
      "dog -> Lemma('andiron.n.01.dog') -> Synset('andiron.n.01')\n",
      "dog -> Lemma('chase.v.01.dog') -> Synset('chase.v.01')\n"
     ]
    }
   ],
   "source": [
    "ex_lemmas = wordnet.lemmas(\"dog\")\n",
    "for lemma in ex_lemmas:\n",
    "    print(\"{} -> {} -> {}\".format(lemma.name(), lemma, lemma.synset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaciones\n",
    "\n",
    "Como decíamos al principio, WordNet es más que un diccionario o un traductor, se trata de una **red de conceptos** que nos permite buscar relaciones entre significados de una forma extremadamente fácil e interesante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset y las relaciones semánticas\n",
    "\n",
    "Los elementos de tipo Synset definen algunas relaciones que podemos explorar. Estas son las más interesantes (puedes consultar la lista completa [aquí](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Synset)):\n",
    "\n",
    " * hiperónimos\n",
    " * hipónimos\n",
    " * holónimos\n",
    " * merónimos\n",
    " \n",
    "#### Hiperónimos e hipónimos\n",
    "La hiperonimia e hiponimia codifican relaciones a nivel de significado. Un **hipónimo** concreta el significado de su **hiperónimo**; así, \"mesa\" es más específico que \"mueble\", y \"altar\" es un tipo particular de \"mesa\".\n",
    "\n",
    "Podemos consultar los hiperónimos de un determinado synset con `.hypernyms()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hyperónimos del Synset('sleep_together.v.01')</caption><tr><th>hyp-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('copulate.v.01')</td><td>copulate, mate, pair, couple</td><td>Birds mate in the Spring</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hypernym in my_synset.hypernyms():\n",
    "    lemmas = [lemma.name() for lemma in hypernym.lemmas()]\n",
    "    data.append([hypernym, ', '.join(lemmas), '</br>'.join(hypernym.examples())])\n",
    "    \n",
    "display_table(data, [\"hyp-synset\", \"lemmas\", \"examples\"], caption=\"Hyperónimos del {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de los hiperónimos a nivel de significado, también existen **a nivel de instancia (`instance_hypernyms`)** (igual con los hipónimos). Por ejemplo, si hemos encontrado en un texto una entidad ([NER](https://es.wikipedia.org/wiki/Reconocimiento_de_entidades_nombradas)) como `Vargas Llosa`, gracias a WordNet podemos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ha buscado: Beethoven\n",
      "beethoven.n.01 is a composer.n.01\n",
      "Otras formas de llamarlo son: Beethoven, van_Beethoven, Ludwig_van_Beethoven\n",
      "Su 'definición' es: German composer of instrumental music (especially symphonic and chamber music); continued to compose after he lost his hearing (1770-1827)\n"
     ]
    }
   ],
   "source": [
    "q = \"Beethoven\"  # Puedes probar con otros como p. ej.: Vargas_Llosa, Zweig, Einstein\n",
    "\n",
    "ner = wordnet.synsets(q)[0]  # Recoge el primer resultado\n",
    "hiperonimos = ner.instance_hypernyms()[0]  # Busca sus hiperónimos y quédate con el primero\n",
    "\n",
    "print(\"Ha buscado: {}\".format(q))\n",
    "print(\"{} is a {}\".format(ner.name(), hiperonimos.name()))  # Su hiperónimo me dice su profesión!!\n",
    "print(\"Otras formas de llamarlo son: {}\".format(', '.join([it.name() for it in ner.lemmas()])))\n",
    "print(\"Su 'definición' es: {}\".format(ner.definition()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos casos, por ejemplo, el hiperónimo de un un escritor concreto es la categoría `escritor` puesto que generaliza su significado.\n",
    "\n",
    "También podemos ver los hipónimos de un determinado synset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Hipónimos del Synset('sleep_together.v.01')</caption><tr><th>hyponym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('fornicate.v.01')</td><td>fornicate</td><td></td></tr><tr><td>Synset('take.v.35')</td><td>take, have</td><td>He had taken this woman when she was most vulnerable</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for hyponym in my_synset.hyponyms():\n",
    "    lemmas = [lemma.name() for lemma in hyponym.lemmas()]\n",
    "    data.append([hyponym, ', '.join(lemmas), '</br>'.join(hyponym.examples())])\n",
    "    \n",
    "display_table(data, [\"hyponym-synset\", \"lemmas\", \"examples\"], caption=\"Hipónimos del {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holónimos y merónimos\n",
    "Las relaciones de holonimia y meronimia codifican relaciones entre el todo y sus partes. Un puerta (de coche) es una parte del coche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_synset = wordnet.synset(\"hand.n.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes cambiar el valor almacenado en la variable `my_synset` para obtener otros resultados en las siguientes celdas. A lo mejor tienes que cambiar el método `.part_holonyms()` por otros métodos para averiguar otros tipos de holónimos, como `.member_holonyms()` o `.substance_holonyms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Holónimos del Synset('hand.n.01')</caption><tr><th>holonym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('arm.n.01')</td><td>arm</td><td></td></tr><tr><td>Synset('homo.n.02')</td><td>homo, man, human_being, human</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for holonym in my_synset.part_holonyms():\n",
    "    lemmas = [lemma.name() for lemma in holonym.lemmas()]\n",
    "    data.append([holonym, ', '.join(lemmas), '</br>'.join(holonym.examples())])\n",
    "    \n",
    "display_table(data, [\"holonym-synset\", \"lemmas\", \"examples\"], caption=\"Holónimos del {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, para ver los merónimos de un Synset, usaremos `.member_meronyms()`, `.substance_meronyms()`, `.part_meronyms()`, dependiendo del tipo de relación que tengan entre sí holónimo y merónimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Merónimos del Synset('hand.n.01')</caption><tr><th>meronym-synset</th><th>lemmas</th><th>examples</th></tr><tr><td>Synset('ball.n.10')</td><td>ball</td><td>the ball at the base of the thumb</br>he stood on the balls of his feet</td></tr><tr><td>Synset('digital_arteries.n.01')</td><td>digital_arteries, arteria_digitalis</td><td></td></tr><tr><td>Synset('finger.n.01')</td><td>finger</td><td>her fingers were long and thin</td></tr><tr><td>Synset('intercapitular_vein.n.01')</td><td>intercapitular_vein, vena_intercapitalis</td><td></td></tr><tr><td>Synset('metacarpal_artery.n.01')</td><td>metacarpal_artery, arteria_metacarpea</td><td></td></tr><tr><td>Synset('metacarpal_vein.n.01')</td><td>metacarpal_vein, vena_metacarpus</td><td></td></tr><tr><td>Synset('metacarpus.n.01')</td><td>metacarpus</td><td></td></tr><tr><td>Synset('palm.n.01')</td><td>palm, thenar</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for meronym in my_synset.part_meronyms():\n",
    "    lemmas = [lemma.name() for lemma in meronym.lemmas()]\n",
    "    data.append([meronym, ', '.join(lemmas), '</br>'.join(meronym.examples())])\n",
    "    \n",
    "display_table(data, [\"meronym-synset\", \"lemmas\", \"examples\"], caption=\"Merónimos del {}\".format(my_synset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los lemmas y sus relaciones\n",
    "También podemos consultar las relaciones de los lemas. Las dos más interesantes (consulta la [lista completa](http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Lemma)) son:\n",
    "\n",
    " - antónimos\n",
    " - formas derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lemma = wordnet.lemma(\"fast.a.01.fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antónimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Antónimos del Lemma('fast.a.01.fast')</caption><tr><th>antonym-lemma</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('slow.a.01.slow')</td><td>slow</td><td>a slow walker</br>the slow lane of traffic</br>her steps were slow</br>he was slow in reacting to the news</br>slow but steady growth</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang = 'eng'\n",
    "data = []\n",
    "for item in my_lemma.antonyms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "    \n",
    "display_table(data, [\"antonym-lemma\", \"lemmas\", \"examples\"], caption=\"Antónimos del {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formas derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Formas derivadas del Lemma('fast.a.01.fast')</caption><tr><th>derivationally-related-forms</th><th>lemmas</th><th>examples</th></tr><tr><td>Lemma('speed.n.02.fastness')</td><td>rapidez</br>velocidad</td><td>the project advanced with gratifying speed</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang = 'spa'\n",
    "data = []\n",
    "\n",
    "for item in my_lemma.derivationally_related_forms():\n",
    "    lemmas = item.synset().lemma_names(lang=lang)\n",
    "    data.append([item, '</br>'.join(lemmas), '</br>'.join(item.synset().examples())])\n",
    "\n",
    "display_table(data, [\"derivationally-related-forms\", \"lemmas\", \"examples\"],\n",
    "              caption=\"Formas derivadas del {}\".format(my_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las relaciones entre un elemento y sus vecinos permiten explorar la red de conceptos buscando términos relacionados con una palabra (lema) dada o bien con un concepto (synset) determinado. Sin embargo, esta estructura de relaciones nos permite también abordar problemas mucho más ambiciosos, como la expansión de búsquedas, la medición de la distancia semántica o la desambiguación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Expansión de búsquedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expansión de búsquedas es una de las técnicas que ha hecho que los buscadores hayan avanzado tanto en los últimos años. Consiste en generalizar a partir de la búsqueda del usuario a palabras que probablemente también le interesen porque están muy relacionadas semánticamente.\n",
    "\n",
    "Para ello podemos utilizar estas redes de conceptos. Por ejemplo, si el usuario ha introducido `dalmatian` como término de búsqueda, podemos buscar synsets en los que aparece, expandir la búsqueda a todos los synsets relacionados y finalmente expandirla a todos sus hiperónimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Búsqueda original: dalmatian\n",
      "Expandida a synsets: carriage_dog, dalmatian, Dalmatian, coach_dog\n",
      "Expandida a hiperónimos: carriage_dog, Dalmatian, domestic_dog, European, dog, coach_dog, Canis_familiaris, dalmatian\n"
     ]
    }
   ],
   "source": [
    "q = \"dalmatian\"\n",
    "print(\"Búsqueda original: {}\".format(q))\n",
    "\n",
    "# Synsets\n",
    "synsets = wordnet.synsets(q)\n",
    "\n",
    "# Lemas de otros synsets\n",
    "def gather_lemmas(synset_list):\n",
    "    lemmas = []\n",
    "    for synset in synset_list:\n",
    "        lemmas += synset.lemma_names()\n",
    "    return lemmas\n",
    "    \n",
    "expanded_query = [q] + gather_lemmas(synsets)\n",
    "print(\"Expandida a synsets: {}\".format(', '.join(set(expanded_query))))\n",
    "\n",
    "# Lemas de sus hiperónimos:\n",
    "for synset in synsets:\n",
    "    expanded_query += gather_lemmas(synset.hypernyms())\n",
    "\n",
    "print(\"Expandida a hiperónimos: {}\".format(', '.join(set(expanded_query))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener muchos más términos de búsqueda podremos recuperar muchos más documentos de nuestro corpus en caso de que la búsqueda original ofreciera un número insuficiente de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra aplicación muy habitual cuando se dispone de una red de conceptos es medir la distancia semántica entre significados. Algunas situaciones en las que puede plantearse esta necesidad son la evaluación de traductores automáticos (cuál se ha separado menos del significado original) o la desambiguación (ante un mismo lema con varios significados, podemos asignarle una probabilidad a cada uno de ellos según la distancia a la temática del documento).\n",
    "\n",
    "Esta aplicación es tan demandada que NLTK implementa los principales algoritmos para calcular esta medida. Por ejemplo, dados tres significados `dog.n.01`, `cat.n.01` y `tiger.n.01`, veamos cuál es la distancia entre ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre el Synset('dog.n.01') y el Synset('cat.n.01') con este algoritmo es de 0.2000.\n"
     ]
    }
   ],
   "source": [
    "synset1 = wordnet.synset(\"dog.n.01\")\n",
    "synset2 = wordnet.synset(\"cat.n.01\")\n",
    "sim = wordnet.path_similarity(synset1, synset2)\n",
    "\n",
    "print(\"La similitud entre el {} y el {} con este algoritmo es de {:0.4f}.\".format(synset1, synset2, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Con `{:0.4f}` lo que estamos haciendo es formatear el número de manera que nos muestre 4 decimales.)\n",
    "\n",
    "Vamos a definir ahora una lista en las que incorporaremos todas las funciones que ofrece WordNet para el cálculo de la similaridad entre dos synsets (en las [referencias](#Referencias) se incluye un artículo en el que se detallan estos algoritmos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métodos básicos para calcular similitud entre dos términos\n",
    "methods = [('path_similarity', wordnet.path_similarity),\n",
    "           ('Leacock-Chodorow', wordnet.lch_similarity),\n",
    "           ('Wu-Palmer', wordnet.wup_similarity),]\n",
    "\n",
    "# Algunos algoritmos necesitan un corpus para utilizarlo como referencia\n",
    "from nltk.corpus import wordnet_ic, genesis\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "genesis_ic = wordnet.ic(genesis, False, 0.0) # Esto puede tardar un poco la primera vez\n",
    "\n",
    "methods_ic = [('Resnik + Brown', lambda u,v: wordnet.res_similarity(u, v, brown_ic)),\n",
    "              ('Resnik + Semcor', lambda u,v: wordnet.res_similarity(u, v, semcor_ic)),\n",
    "              ('Resnik + Genesis', lambda u,v: wordnet.res_similarity(u, v, genesis_ic)),\n",
    "                \n",
    "              ('Jiang-Conrath + Brown', lambda u,v: wordnet.jcn_similarity(u, v, brown_ic)),\n",
    "              ('Jiang-Conrath + Semcor', lambda u,v: wordnet.jcn_similarity(u, v, semcor_ic)),\n",
    "              ('Jiang-Conrath + Genesis', lambda u,v: wordnet.jcn_similarity(u, v, genesis_ic)),\n",
    "           \n",
    "              ('Lin + Brown', lambda u,v: wordnet.lin_similarity(u, v, brown_ic)),\n",
    "              ('Lin + Semcor', lambda u,v: wordnet.lin_similarity(u, v, semcor_ic)),\n",
    "              ('Lin + Genesis', lambda u,v: wordnet.lin_similarity(u, v, genesis_ic)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también una función para mostrar los resultados de nuestros cálculos en una tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_format = \"{0:.4f}\"\n",
    "\n",
    "def compute_distances(item_list, method_list):\n",
    "    data = []\n",
    "    it1 = item_list[0]\n",
    "    for key,method in method_list:\n",
    "        max_similarity = method(it1, it1)\n",
    "        row = [float_format.format(1.0),]\n",
    "\n",
    "        for it2 in item_list[1:]:\n",
    "            similitud = method(it1, it2)/max_similarity  # Normalized by 'similarity(it1, it1)'\n",
    "            row.append(float_format.format(similitud)) \n",
    "        data.append([key] + row)\n",
    "\n",
    "    columns = [\"{} - {}\".format(item_list[0].name(), it.name()) for it in item_list]\n",
    "    display_table(data, [\"Método\"] + columns, caption=\"Similitud normalizada entre '{}'\".format(it1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los elementos anteriores, la lista de algoritmos y la función auxiliar, podemos empezar a calcular cosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('dog.n.01')'</caption><tr><th>Método</th><th>dog.n.01 - dog.n.01</th><th>dog.n.01 - cat.n.01</th><th>dog.n.01 - tiger.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.2000</td><td>0.1667</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.5576</td><td>0.5074</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.9231</td><td>0.7602</td></tr><tr><td>Resnik + Brown</td><td>1.0000</td><td>0.8785</td><td>0.2470</td></tr><tr><td>Resnik + Semcor</td><td>1.0000</td><td>0.9373</td><td>0.2355</td></tr><tr><td>Resnik + Genesis</td><td>1.0000</td><td>0.7236</td><td>0.1445</td></tr><tr><td>Jiang-Conrath + Brown</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Jiang-Conrath + Semcor</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Jiang-Conrath + Genesis</td><td>1.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><td>Lin + Brown</td><td>1.0000</td><td>0.8768</td><td>0.2091</td></tr><tr><td>Lin + Semcor</td><td>1.0000</td><td>0.8863</td><td>0.1869</td></tr><tr><td>Lin + Genesis</td><td>1.0000</td><td>0.8044</td><td>0.0000</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dog = wordnet.synset(\"dog.n.01\")\n",
    "cat = wordnet.synset(\"cat.n.01\")\n",
    "tiger = wordnet.synset(\"tiger.n.01\")\n",
    "animals = [dog, cat, tiger] # Aquí puedes añadir más synsets\n",
    "\n",
    "compute_distances(animals, methods + methods_ic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar, todos los algoritmos dan una similitud del 100 % para un synset comparado con sí mismo :D En cuanto a si consideramos un perro más parecido a un gato o a un tigre... parece que gana el gato, pero no siempre con holgura (mira los resultados que salen para Leacock-Chodorow).\n",
    "\n",
    "Por supuesto, también es interesante hacerlo con entidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein is a physicist\n",
      "Austen is a writer\n",
      "Zweig is a writer\n",
      "Cousteau is an explorer\n",
      "Akhenaton is a king\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('einstein.n.01')'</caption><tr><th>Método</th><th>einstein.n.01 - einstein.n.01</th><th>einstein.n.01 - austen.n.01</th><th>einstein.n.01 - zweig.n.01</th><th>einstein.n.01 - cousteau.n.01</th><th>einstein.n.01 - akhenaton.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.1429</td><td>0.1429</td><td>0.1667</td><td>0.1250</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.4651</td><td>0.4651</td><td>0.5074</td><td>0.4283</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.6000</td><td>0.6000</td><td>0.6316</td><td>0.5714</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><caption>Similitud normalizada entre 'Synset('zweig.n.01')'</caption><tr><th>Método</th><th>zweig.n.01 - zweig.n.01</th><th>zweig.n.01 - einstein.n.01</th><th>zweig.n.01 - austen.n.01</th><th>zweig.n.01 - cousteau.n.01</th><th>zweig.n.01 - akhenaton.n.01</th></tr><tr><td>path_similarity</td><td>1.0000</td><td>0.1429</td><td>0.3333</td><td>0.1667</td><td>0.1250</td></tr><tr><td>Leacock-Chodorow</td><td>1.0000</td><td>0.4651</td><td>0.6980</td><td>0.5074</td><td>0.4283</td></tr><tr><td>Wu-Palmer</td><td>1.0000</td><td>0.6000</td><td>0.6000</td><td>0.6316</td><td>0.5714</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = wordnet.synset(\"Einstein.n.01\")\n",
    "p2 = wordnet.synset(\"Austen.n.01\")\n",
    "p3 = wordnet.synset(\"Zweig.n.01\")\n",
    "p4 = wordnet.synset(\"Cousteau.n.01\")\n",
    "p5 = wordnet.synset(\"akhenaton.n.01\")\n",
    "people = [p1, p2, p3, p4, p5] # TODO: Aquí puedes añadir más synsets\n",
    "\n",
    "for it in people:\n",
    "    hyp = it.instance_hypernyms()[0]\n",
    "    if hyp.lemmas()[0].name().startswith((\"a\", \"e\", \"i\", \"o\", \"u\")):\n",
    "        print(\"{} is an {}\".format(it.lemmas()[0].name(), hyp.lemmas()[0].name()))\n",
    "    else:\n",
    "        print(\"{} is a {}\".format(it.lemmas()[0].name(), hyp.lemmas()[0].name()))\n",
    "\n",
    "compute_distances([p1, p2, p3, p4, p5], methods)\n",
    "compute_distances([p3, p1, p2, p4, p5], methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, Einstein se parece más a Cousteau que a Austen o a Zweig, y está más alejado de Akenatón (pero tampoco por mucho...). Sin embargo, Zweig claramente se parece más a Austen, porque ambos fueron escritores, que a los demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desambiguación\n",
    "\n",
    "El problema clásico y ¿sin solución definitiva? del PLN es desambiguar el significado de una palabra. Una forma de abordarlo que podemos intentar con lo que sabemos hasta ahora es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"El banco presta dinero a cambio de un interés\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos tokenizar y realizar el análisis sintáctico de una oración. Con ello obtenemos las palabras individuales y la PoS de cada una de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bank', 'n'), ('money', 'n'), ('interest', 'n')]\n"
     ]
    }
   ],
   "source": [
    "sentence = [(\"bank\", \"n\"), (\"lend\", \"v\"), (\"money\", \"n\"), (\"interest\", \"n\")]\n",
    "\n",
    "# Eliminamos todo menos los nombres\n",
    "sentence = [(it, pos) for it, pos in sentence if pos==\"n\"]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente tenemos un problema de desambiguación puesto que cada una de estas palabras puede tener diferentes significados. Vamos a listarlos todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Significados de bank:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('bank.n.01')</td><td>bank</td><td>sloping land (especially the slope beside a body of water)</td></tr><tr><td>Synset('depository_financial_institution.n.01')</td><td>depository_financial_institution, bank, banking_concern, banking_company</td><td>a financial institution that accepts deposits and channels the money into lending activities</td></tr><tr><td>Synset('bank.n.03')</td><td>bank</td><td>a long ridge or pile</td></tr><tr><td>Synset('bank.n.04')</td><td>bank</td><td>an arrangement of similar objects in a row or in tiers</td></tr><tr><td>Synset('bank.n.05')</td><td>bank</td><td>a supply or stock held in reserve for future use (especially in emergencies)</td></tr><tr><td>Synset('bank.n.06')</td><td>bank</td><td>the funds held by a gambling house or the dealer in some gambling games</td></tr><tr><td>Synset('bank.n.07')</td><td>bank, cant, camber</td><td>a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force</td></tr><tr><td>Synset('savings_bank.n.02')</td><td>savings_bank, coin_bank, money_box, bank</td><td>a container (usually with a slot in the top) for keeping money at home</td></tr><tr><td>Synset('bank.n.09')</td><td>bank, bank_building</td><td>a building in which the business of banking transacted</td></tr><tr><td>Synset('bank.n.10')</td><td>bank</td><td>a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Significados de money:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('money.n.01')</td><td>money</td><td>the most common medium of exchange; functions as legal tender</td></tr><tr><td>Synset('money.n.02')</td><td>money</td><td>wealth reckoned in terms of money</td></tr><tr><td>Synset('money.n.03')</td><td>money</td><td>the official currency issued by a government or national bank</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Significados de interest:</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><td>Synset('interest.n.01')</td><td>interest, involvement</td><td>a sense of concern with and curiosity about someone or something</td></tr><tr><td>Synset('sake.n.01')</td><td>sake, interest</td><td>a reason for wanting something done</td></tr><tr><td>Synset('interest.n.03')</td><td>interest, interestingness</td><td>the power of attracting or holding one's attention (because it is unusual or exciting etc.)</td></tr><tr><td>Synset('interest.n.04')</td><td>interest</td><td>a fixed charge for borrowing money; usually a percentage of the amount borrowed</td></tr><tr><td>Synset('interest.n.05')</td><td>interest, stake</td><td>(law) a right or legal share of something; a financial involvement with something</td></tr><tr><td>Synset('interest.n.06')</td><td>interest, interest_group</td><td>(usually plural) a social group whose members control some field of activity and who have common aims</td></tr><tr><td>Synset('pastime.n.01')</td><td>pastime, interest, pursuit</td><td>a diversion that occupies one's time and thoughts (usually pleasantly)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, pos in sentence:\n",
    "    display(HTML(\"<strong>Significados de {}:</strong>\".format(word)))\n",
    "\n",
    "    synsets = wordnet.synsets(word, pos=pos)\n",
    "    data = []\n",
    "    for s in synsets:\n",
    "        data.append([s, ', '.join([it.name() for it in s.lemmas()]), s.definition()])\n",
    "        \n",
    "    display_table(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La estrategia que vamos a seguir es probar todas las combinaciones posibles y quedarnos con aquella que ofrezca la mayor similitud entre sus componentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "¡Hay 210 combinaciones posibles!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Las 10 primeras son:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table align=\"left\"><tr><th>score</th><th>bank</th><th>money</th><th>interest</th></tr><tr><td>0.4857</td><td>bank.n.06: bank</td><td>money.n.02: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3818</td><td>bank.n.06: bank</td><td>money.n.01: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3778</td><td>bank.n.04: bank</td><td>money.n.01: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3778</td><td>bank.n.04: bank</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3667</td><td>bank.n.06: bank</td><td>money.n.03: money</td><td>interest.n.05: interest, stake</td></tr><tr><td>0.3651</td><td>bank.n.06: bank</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3611</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.01: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3611</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.02: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3576</td><td>bank.n.04: bank</td><td>money.n.03: money</td><td>interest.n.06: interest, interest_group</td></tr><tr><td>0.3436</td><td>depository_financial_institution.n.01: depository_financial_institution, bank, banking_concern, banking_company</td><td>money.n.03: money</td><td>interest.n.06: interest, interest_group</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Y la ganadora, con una puntuación de 0.4857142857142857, es:</strong><ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>bank.n.06</strong>: the funds held by a gambling house or the dealer in some gambling games</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>money.n.02</strong>: wealth reckoned in terms of money</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<li><strong>interest.n.05</strong>: (law) a right or legal share of something; a financial involvement with something</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_options = [wordnet.synsets(word, pos=pos) for word, pos in sentence]\n",
    "\n",
    "import itertools\n",
    "all_combinations = list(itertools.product(*sentence_options))\n",
    "display(HTML(\"¡Hay {} combinaciones posibles!\".format(len(all_combinations))))\n",
    "\n",
    "data = {}\n",
    "for comb in all_combinations:\n",
    "    sim = 0\n",
    "    for pair in itertools.combinations(comb, r=2):\n",
    "        if pair[0].pos() == pair[1].pos():\n",
    "            sim += wordnet.path_similarity(pair[0], pair[1])\n",
    "    data[comb] = sim\n",
    "\n",
    "import operator\n",
    "sorted_data = sorted(data.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Conservamos solo las primeras 10\n",
    "display(HTML(\"Las 10 primeras son:\"))\n",
    "top10 = sorted_data[:10]\n",
    "\n",
    "# Imprimimos los lemmas\n",
    "data_to_display = []\n",
    "for it, sim in top10:\n",
    "    row = [\"{:0.4f}\".format(sim)]\n",
    "    for synset in it:\n",
    "        cell_text = \"{}: {}\".format(synset.name(), ', '.join([lema.name() for lema in synset.lemmas()]))\n",
    "        row.append(cell_text)\n",
    "    data_to_display.append(row)\n",
    "\n",
    "display_table(data_to_display, headers=[\"score\"] + [word for word, pos in sentence])\n",
    "\n",
    "# Imprimimos el ganador\n",
    "winner, sim = top10[0]\n",
    "display(HTML(\"<strong>Y la ganadora, con una puntuación de {}, es:</strong><ul>\".format(sim)))\n",
    "for it in winner:\n",
    "    display(HTML(\"<li><strong>{}</strong>: {}</li>\".format(it.name(), it.definition())))\n",
    "display(HTML(\"</ul>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡No está mal! Aunque es mejorable. ¿Cómo podemos mejorar este resultado de manera fácil? Si tenemos información sobre el contexto, por ejemplo, si sabemos que la oración aparece en una noticia de la sección económica de un periódico, entonces podemos utilizar como input la frecuencia relativa de nuestros significados dentro de ese corpus.\n",
    "\n",
    "Pero eso ya para otro día..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Referencias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Global Wordnet Association](http://globalwordnet.org/): muy interesante la colección de links a wordnets en otros idiomas\n",
    " * [Universal Networking Language](https://en.wikipedia.org/wiki/Universal_Networking_Language): otra iniciativa de codificación unívoca del lenguaje. Uno de los grupos de desarrollo está en la UPM-Informática.\n",
    " * [«Medida de distancia semántica en grafos UNL»](https://www.dropbox.com/s/pygvolndftoshz9/GarciaSogo_Javier%20-%20Medida%20de%20distancia%20sem%C3%A1ntica%20en%20grafos%20UNL.pdf?dl=0) (Javier G. Sogo, 2015): utilizando UNL y WordNet se propone una metodología para evaluar la distancia semántica entre dos oraciones y así valorar el funcionamiento de dos traductores automáticos. Incluye documentación sobre los algoritmos de distancia semántica utilizados en la ontología de WordNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
